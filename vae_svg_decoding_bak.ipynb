{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JBvIrN0dYfN3"},"source":["# Imports"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-FWeKpn8VuDl","colab":{}},"source":["from __future__ import print_function\n","\n","import copy\n","import logging\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import re\n","import tensorflow as tf\n","import warnings\n","\n","# from colabtools import publish\n","from tensor2tensor.utils import registry\n","from magenta.models import svg_vae\n","from magenta.models.svg_vae import svg_utils\n","from tensor2tensor.layers import common_layers\n","from tensor2tensor.utils import trainer_lib\n","\n","\n","tfe = tf.contrib.eager\n","Modes = tf.estimator.ModeKeys\n","\n","\n","tf.enable_eager_execution()\n","\n","logging.getLogger(\"mlperf_compliance\").setLevel(logging.ERROR)\n","warnings.simplefilter(\"ignore\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"I-RBCz5S2gD1"},"source":["# Code"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hMUYnd3NtnF3"},"source":["## utils for initializing the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GaLOFznSO2Ip","colab":{}},"source":["def initialize_model(problem_name, data_dir, hparam_set, hparams, model_name,\n","                     ckpt_dir, split=Modes.TRAIN):\n","  \"\"\"Returns an initialized model, dataset iterator and hparams.\"\"\"\n","  tf.reset_default_graph()\n","  \n","  # create hparams and get glyphazzn problem definition\n","  hparams = trainer_lib.create_hparams(hparam_set, hparams, data_dir=data_dir,\n","                                       problem_name=problem_name)\n","  problem = registry.problem(problem_name)\n","  \n","  # get model definition\n","  ModelClass = registry.model(model_name)\n","  model = ModelClass(hparams, mode=Modes.PREDICT,\n","                     problem_hparams=hparams.problem_hparams)\n","  \n","  # create dataset iterator from problem definition\n","  dataset = problem.dataset(Modes.PREDICT, dataset_split=split,\n","                            data_dir=data_dir, shuffle_files=False,\n","                            hparams=hparams).batch(2)\n","  iterator = tfe.Iterator(dataset)\n","  \n","  # finalize/initialize model\n","  output, extra_losses = model(iterator.next())  # creates ops to be initialized\n","  model.initialize_from_ckpt(ckpt_dir)  # initializes ops\n","  \n","  return model, iterator, hparams"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3XtY17EajF71"},"source":["## utils for running the model with manipulated latent spaces"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2B4ImhY1jQ6S","colab":{}},"source":["def get_bottleneck(features, model):\n","  \"\"\"Retrieve latent encoding for given input pixel image in features dict.\"\"\"\n","  features = features.copy()\n","  # the presence of a 'bottleneck' feature with 0 dimensions indicates that the\n","  # model should return the bottleneck from the input image\n","  features['bottleneck'] = tf.zeros((0, 128))\n","  return model(features)[0]\n","\n","\n","def infer_from_bottleneck(features, bottleneck, model, out='cmd'):\n","  \"\"\"Returns a sample from a decoder, conditioned on the given a latent.\"\"\"\n","  features = features.copy()\n","  \n","  # set bottleneck which we're decoding from\n","  features['bottleneck'] = bottleneck\n","\n","  # reset inputs/targets. This guarantees that the decoder is only being\n","  # conditioned on the given bottleneck.\n","  batch_size = tf.shape(bottleneck)[:1].numpy().tolist()\n","  features['inputs'] = tf.zeros(\n","      batch_size + tf.shape(features['inputs'])[1:].numpy().tolist())\n","  features['targets'] = tf.zeros(\n","      batch_size + tf.shape(features['targets'])[1:].numpy().tolist())\n","  features['targets_psr'] = tf.zeros(\n","      batch_size + tf.shape(features['targets_psr'])[1:].numpy().tolist())\n","  \n","  if out == 'cmd':\n","    # using the SVG Decoder\n","    return model.infer(features, decode_length=0)\n","  # using the Image Decoder (from the Image VAE)\n","  return model(features)\n","\n","\n","def merge_features(features_list):\n","  new_features = {}\n","  for k in features_list[0].keys():\n","    all_vs = [features[k] for features in features_list]\n","    new_features[k] = tf.concat(all_vs, axis=0)\n","  return new_features"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"doR9EP687k_X"},"source":["## utils for postprocessing svg htmls"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"H176cH8ao85K","colab":{}},"source":["start = (\"\"\"<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.\"\"\"\n","         \"\"\"w3.org/1999/xlink\" width=\"256px\" height=\"256px\" style=\"-ms-trans\"\"\"\n","         \"\"\"form: rotate(360deg); -webkit-transform: rotate(360deg); transfo\"\"\"\n","         \"\"\"rm: rotate(360deg);\" preserveAspectRatio=\"xMidYMid meet\" viewBox\"\"\"\n","         \"\"\"=\"0 0 24 24\"><path d=\\\"\"\"\")\n","end = \"\"\"\\\" fill=\"currentColor\"/></svg>\"\"\"\n","\n","COMMAND_RX = re.compile(\"([MmLlHhVvCcSsQqTtAaZz])\")\n","FLOAT_RX = re.compile(\"[-+]?[0-9]*\\.?[0-9]+(?:[eE][-+]?[0-9]+)?\")\n","\n","\n","def svg_html_to_path_string(svg):\n","  return svg.replace(start, '').replace(end, '')\n","\n","\n","def _tokenize(pathdef):\n","  \"\"\"Returns each svg token from path list.\"\"\"\n","  # e.g.: 'm0.1-.5c0,6' -> m', '0.1, '-.5', 'c', '0', '6'\n","  for x in COMMAND_RX.split(pathdef):\n","    if x != '' and x in 'MmLlHhVvCcSsQqTtAaZz':\n","      yield x\n","    for token in FLOAT_RX.findall(x):\n","      yield token\n","\n","\n","def path_string_to_tokenized_commands(path):\n","  \"\"\"Tokenizes the given path string.\n","\n","  E.g.:\n","      Given M 0.5 0.5 l 0.25 0.25 z\n","      Returns [['M', '0.5', '0.5'], ['l', '0.25', '0.25'], ['z']]\n","  \"\"\"\n","  new_path = []\n","  current_cmd = []\n","  for token in _tokenize(path):\n","    if len(current_cmd) > 0:\n","      if token in 'MmLlHhVvCcSsQqTtAaZz':\n","        # cmd ended, convert to vector and add to new_path\n","        new_path.append(current_cmd)\n","        current_cmd = [token]\n","      else:\n","        # add arg to command\n","        current_cmd.append(token)\n","    else:\n","      # add to start new cmd\n","      current_cmd.append(token)\n","\n","  if current_cmd:\n","    # process command still unprocessed\n","    new_path.append(current_cmd)\n","\n","  return new_path\n","\n","\n","def separate_substructures(tokenized_commands):\n","  \"\"\"Returns a list of SVG substructures.\"\"\"\n","  # every moveTo command starts a new substructure\n","  # an SVG substructure is a subpath that closes on itself\n","  # such as the outter and the inner edge of the character `o`\n","  substructures = []\n","  curr = []\n","  for cmd in tokenized_commands:\n","    if cmd[0] in 'mM' and len(curr) > 0:\n","      substructures.append(curr)\n","      curr = []\n","    curr.append(cmd)\n","  if len(curr) > 0:\n","    substructures.append(curr)\n","  return substructures\n","\n","\n","def postprocess(svg, dist_thresh=2., skip=False):\n","  path = svg_html_to_path_string(svg)\n","  svg_template = svg.replace(path, '{}')\n","  tokenized_commands = path_string_to_tokenized_commands(path)\n","  \n","  dist = lambda a, b: np.sqrt((float(a[0]) - float(b[0]))**2 +\n","                              (float(a[1]) - float(b[1]))**2)\n","  are_close_together = lambda a, b, t: dist(a, b) < t\n","  \n","  # first, go through each start/end point and merge if they're close enough\n","  # together (that is, make end point the same as the start point).\n","  # TODO: there are better ways of doing this, in a way that propagates error\n","  # back (so if total error is 0.2, go through all N commands in this\n","  # substructure and fix each by 0.2/N (unless they have 0 vertical change))\n","  substructures = separate_substructures(tokenized_commands)\n","  previous_substructure_endpoint = (0., 0.,)\n","  for substructure in substructures:\n","    # first, if the last substructure's endpoint was updated, we must update\n","    # the start point of this one to reflect the opposite update\n","    substructure[0][-2] = str(float(substructure[0][-2]) -\n","                              previous_substructure_endpoint[0])\n","    substructure[0][-1] = str(float(substructure[0][-1]) -\n","                              previous_substructure_endpoint[1])\n","    \n","    start = list(map(float, substructure[0][-2:]))\n","    curr_pos = (0., 0.)\n","    for cmd in substructure:\n","      curr_pos, _ = svg_utils._update_curr_pos(curr_pos, cmd, (0., 0.))\n","    if are_close_together(start, curr_pos, dist_thresh):\n","      new_point = np.array(start)\n","      previous_substructure_endpoint = ((new_point[0] - curr_pos[0]),\n","                                        (new_point[1] - curr_pos[1]))\n","      substructure[-1][-2] = str(float(substructure[-1][-2]) +\n","                                 (new_point[0] - curr_pos[0]))\n","      substructure[-1][-1] = str(float(substructure[-1][-1]) +\n","                                 (new_point[1] - curr_pos[1]))\n","      if substructure[-1][0] in 'cC':\n","        substructure[-1][-4] = str(float(substructure[-1][-4]) +\n","                                   (new_point[0] - curr_pos[0]))\n","        substructure[-1][-3] = str(float(substructure[-1][-3]) +\n","                                   (new_point[1] - curr_pos[1]))\n","      \n","  if skip:\n","    return svg_template.format(' '.join([' '.join(' '.join(cmd) for cmd in s)\n","                                         for s in substructures]))\n","  \n","  cosa = lambda x, y: (x[0] * y[0] + x[1] * y[1]) / (\n","      (np.sqrt(x[0]**2 + x[1]**2) * np.sqrt(y[0]**2 +  y[1]**2)))\n","  rotate = lambda a, x, y: (x * np.cos(a) - y * np.sin(a),\n","                            y * np.cos(a) + x * np.sin(a))\n","  # second, gotta find adjacent bezier curves and, if their control points\n","  # are well enough aligned, fully align them\n","  for substructure in substructures:\n","    curr_pos = (0., 0.)\n","    new_curr_pos, _ = svg_utils._update_curr_pos((0., 0.,),\n","                                                 substructure[0], (0., 0.))\n","    \n","    for cmd_idx in range(1, len(substructure)):\n","      prev_cmd = substructure[cmd_idx-1]\n","      cmd = substructure[cmd_idx]\n","      \n","      new_new_curr_pos, _ = svg_utils._update_curr_pos(\n","          new_curr_pos, cmd, (0., 0.))\n","      \n","      if cmd[0] == 'c':\n","        if prev_cmd[0] == 'c':\n","          # check the vectors and update if needed\n","          # previous control pt wrt new curr point\n","          prev_ctr_point = (curr_pos[0] + float(prev_cmd[3]) - new_curr_pos[0],\n","                            curr_pos[1] + float(prev_cmd[4]) - new_curr_pos[1])\n","          ctr_point = (float(cmd[1]), float(cmd[2]))\n","\n","          if -1. < cosa(prev_ctr_point, ctr_point) < -0.95:\n","            # calculate exact angle between the two vectors\n","            angle_diff = (np.pi - np.arccos(cosa(prev_ctr_point, ctr_point)))/2\n","            \n","            # rotate each vector by angle/2 in the correct direction for each.\n","            sign = np.sign(np.cross(prev_ctr_point, ctr_point))\n","            new_ctr_point = rotate(sign * angle_diff, *ctr_point)\n","            new_prev_ctr_point = rotate(-sign * angle_diff, *prev_ctr_point)\n","            \n","            # override the previous control points\n","            # (which has to be wrt previous curr position)\n","            substructure[cmd_idx-1][3] = str(new_prev_ctr_point[0] -\n","                                             curr_pos[0] + new_curr_pos[0])\n","            substructure[cmd_idx-1][4] = str(new_prev_ctr_point[1] -\n","                                             curr_pos[1] + new_curr_pos[1])\n","            substructure[cmd_idx][1] = str(new_ctr_point[0])\n","            substructure[cmd_idx][2] = str(new_ctr_point[1])\n","\n","      curr_pos = new_curr_pos\n","      new_curr_pos = new_new_curr_pos\n","  \n","  return svg_template.format(' '.join([' '.join(' '.join(cmd) for cmd in s)\n","                                       for s in substructures]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TX7aEQlJjJ95"},"source":["## utils for rendering model vector outputs into html svg"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"if-m_z1OFa3K","colab":{}},"source":["means_stdevs = {}\n","\n","def get_means_stdevs(data_dir):\n","  \"\"\"Returns the means and stdev saved in data_dir.\"\"\"\n","  if data_dir not in means_stdevs:\n","    with tf.gfile.Open(os.path.join(data_dir, 'mean.npz'), 'rb') as f:\n","      mean_npz = np.load(f)\n","    with tf.gfile.Open(os.path.join(data_dir, 'stdev.npz'), 'rb') as f:\n","      stdev_npz = np.load(f)\n","    means_stdevs[data_dir] = (mean_npz, stdev_npz)\n","  return means_stdevs[data_dir]\n","\n","\n","def render(tensor, data_dir):\n","  \"\"\"Converts SVG decoder output into HTML svg.\"\"\"\n","  # undo normalization\n","  mean_npz, stdev_npz = get_means_stdevs(data_dir)\n","  tensor = (tensor * stdev_npz) + mean_npz\n","\n","  # convert to html\n","  tensor = svg_utils.make_simple_cmds_long(tensor)\n","  vector = tf.squeeze(tensor, [0, 2])\n","  html = svg_utils.vector_to_svg(vector.numpy(), stop_at_eos=True,\n","                                 categorical=True)\n","\n","  # some aesthetic postprocessing\n","  html = postprocess(html)\n","  html = html.replace('256px', '50px')\n","    \n","  return html"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NnYl0KJUs3qg"},"source":["## utils for rendering, specific to colab"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OGzNK51WuMJq","colab":{}},"source":["def prettify_ax(ax):\n","  ax.grid(False)\n","  ax.set_yticklabels([])\n","  ax.set_xticklabels([])\n","  ax.set_yticks([])\n","  ax.set_xticks([])\n","\n","\n","class OutputStream(object):\n","  \"\"\"Defines how results are rendered in this colab: plt.Axes or html str.\"\"\"\n","\n","  def __init__(self, out, num_rows, num_cols, data_dir):\n","    self.num_cols = num_cols\n","    self.out = out\n","    self.data_dir = data_dir\n","    self.ax_id = 0\n","    if out == 'img':\n","      fig, self.axes = plt.subplots(num_rows, 2 + num_cols,\n","                                    figsize=(8 * num_cols / 10., 2))\n","      fig.subplots_adjust(left=0, top=1, bottom=0, right=1, wspace=0, hspace=0)\n","      self.axes = self.axes.flatten()\n","      for ax in self.axes:\n","        prettify_ax(ax)\n","    else:\n","      self.result_html = ''\n","\n","  def add_output(self, new_output):\n","    if out == 'img':\n","      self.axes[self.ax_id].imshow(np.reshape(new_output, [64, 64]),\n","                                   vmin=0, vmax=1, cmap='gray')\n","    else:\n","      self.result_html += render(new_output, self.data_dir)\n","      self.maybe_add_br()\n","    self.ax_id += 1\n","\n","  def add_spacing(self):\n","    if out == 'cmd':\n","      self.result_html += '&nbsp;' * 15\n","\n","  def add_white(self):\n","    if out == 'img':\n","      self.add_output(np.ones([64, 64]))\n","    else:\n","      self.result_html += ('<div style=\"display:inline-block; '\n","                           'height: 50px; width: 50px;\"></div>')\n","      self.maybe_add_br()\n","      self.ax_id += 1\n","\n","  def maybe_add_br(self):\n","    if self.num_cols != 1 and (self.ax_id + 1) % (self.num_cols + 2) == 0:\n","        self.result_html += '<br />'\n","\n","  def show(self):\n","    if out == 'img':\n","      plt.show()\n","    else:\n","      publish.html(self.result_html)\n","\n","\n","def _tile(features, key, dims):\n","  \"\"\"Helper that creates copies of features['keys'] across given dims.\"\"\"\n","  features[key] = tf.tile(features[key], dims)\n","  return features"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"50DnLHavviED"},"source":["## experiments with manipulating latent spaces"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def class_switch(problem_name, data_dir, hparam_set, hparams, model_name,\n","                 ckpt_dir, out='cmd', split=Modes.TRAIN, ex_id=297):\n","  \"\"\"Decodes one example of each class, conditioned on ex_id-th example.\"\"\"\n","  model, iterator, hparams = initialize_model(\n","      problem_name, data_dir, hparam_set, hparams, model_name,\n","      ckpt_dir, split=split)\n","  \n","  num_classes = hparams.num_categories\n","  \n","  # get the ex_id-th example from the dataset\n","  for i in range(ex_id):\n","    features1 = iterator.next()\n","\n","  print(features1['inputs'].get_shape())\n","  features1['inputs'] = features1['inputs'][0]\n","  print(features1['inputs'].get_shape())\n","  # create output_steam\n","  output_stream = OutputStream(out, 3, 26, data_dir)\n","  output_stream.add_output(features1['inputs'])\n","  output_stream.add_white()\n","\n","  # get bottleneck of the features we selected before\n","  bottleneck1 = get_bottleneck(features1, model)\n","  bottleneck1 = tf.tile(bottleneck1, [num_classes, 1])\n","  \n","  # create class batch\n","  new_features = copy.copy(features1)\n","  clss_batch = tf.reshape([tf.constant([[clss]], dtype=tf.int64) for clss in range(num_classes)], [-1, 1])\n","  new_features['targets_cls'] = clss_batch\n","  new_features['targets_fnt'] = features1['targets_fnt']\n","  new_features['targets'] = features1['targets']\n","  # new_features = _tile(new_features, 'targets_psr', [num_classes, 1, 1])\n","  # inp_target_dim = [num_classes, 1, 1, 1] if out == 'cmd' else [num_classes, 1]\n","  # new_features = _tile(new_features, 'inputs', inp_target_dim)\n","  # new_features = _tile(new_features, 'targets', inp_target_dim)\n","  \n","  # run model\n","  output_batch = infer_from_bottleneck(new_features, bottleneck1, model, out=out)\n","  \n","  should_add_white = {12: 18, 56: 2}\n","\n","  # render outputs and show results\n","  output_batch = output_batch[0] if out == 'img' else output_batch['outputs']\n","  for output in tf.split(output_batch, num_classes):\n","    output_stream.add_output(output)\n","\n","    if output_stream.ax_id in should_add_white.keys():\n","      [output_stream.add_white()\n","       for _ in range(should_add_white[output_stream.ax_id])]\n","  output_stream.show()\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Gu-Jd1ayMyBK","colab":{}},"source":["def interpolation(problem_name, data_dir, hparam_set, hparams, model_name,\n","                  ckpt_dir, out='cmd', split=Modes.TRAIN,\n","                  ex_id=297, ex_id2=110):\n","  \"\"\"Interpolates between two given icons in the dataset.\"\"\"\n","  model, iterator, hparams = initialize_model(\n","      problem_name, data_dir, hparam_set, hparams, model_name,\n","      ckpt_dir, split=split)\n","  \n","  # get both latent spaces we will interpolate\n","  for i in range(ex_id):\n","    features1 = iterator.next()\n","  bottleneck1 = get_bottleneck(features1, model)\n","  \n","  for i in range(ex_id2):\n","    features2 = iterator.next()\n","  bottleneck2 = get_bottleneck(features2, model)\n","\n","  interpolation_weights = np.linspace(0, 1, 11, dtype=np.float32)\n","\n","  # show first latent's input\n","  output_stream = OutputStream(out, 1, len(interpolation_weights), data_dir)\n","  output_stream.add_output(features1['inputs'])\n","  output_stream.add_spacing()\n","\n","  # prepare batch so we can get all interpolations in one go\n","  num_batch = len(interpolation_weights)\n","  new_features = copy.copy(features1)\n","  all_bottlenecks = [(bottleneck1 + alpha * (bottleneck2 - bottleneck1))\n","                     for alpha in interpolation_weights]\n","  all_bottlenecks = tf.reshape(all_bottlenecks, [num_batch, -1])\n","  inputs_targets_dim = [num_batch, 1, 1, 1] if out == 'cmd' else [num_batch, 1]\n","  new_features = _tile(new_features, 'inputs', inputs_targets_dim)\n","  new_features = _tile(new_features, 'targets', inputs_targets_dim)\n","  new_features = _tile(new_features, 'targets_cls', [num_batch, 1])\n","  new_features = _tile(new_features, 'targets_psr', [num_batch, 1, 1])\n","\n","  # run the decoder, conditioned on the bottleneck.\n","  output_batch = infer_from_bottleneck(\n","      new_features, all_bottlenecks, model, out=out)\n","\n","  # render outputs\n","  output_batch = output_batch[0] if out == 'img' else output_batch['outputs']\n","  for output in tf.split(output_batch, num_batch):\n","    output_stream.add_output(output)\n","\n","  if 'targets_cls' in features1:\n","    print('cls={}'.format(features1['targets_cls'][0][0]))\n","\n","  # add final image (direction towards which we were interpolating) and show\n","  output_stream.add_spacing()\n","  output_stream.add_output(features2['inputs'])\n","  output_stream.show()\n","\n","\n","def random_bottleneck(problem_name, data_dir, hparam_set, hparams, model_name,\n","                      ckpt_dir, out='cmd'):\n","  \"\"\"Decodes one example per class given randomly-sampled bottlenecks.\"\"\"\n","  model, iterator, hparams = initialize_model(\n","      problem_name, data_dir, hparam_set, hparams, model_name, ckpt_dir)\n","\n","  num_classes = hparams.num_categories\n","    \n","  # create randomly-sampled bottleneck\n","  features1 = iterator.next()\n","  bottleneck_shape = [num_classes,\n","                      tf.shape(get_bottleneck(features1, model))[-1]]\n","  bottleneck1 = tf.random_normal(bottleneck_shape)\n","  \n","  # create output_steam\n","  output_stream = OutputStream(out, 3, num_classes//3 + 4, data_dir)\n","\n","  # prepare batch so we can get all classes in one go\n","  new_features = copy.copy(features1)\n","  clss_batch = tf.reshape([tf.constant([[clss]], dtype=tf.int64)\n","                           for clss in range(num_classes)], [-1, 1])\n","  new_features['targets_cls'] = clss_batch\n","  new_features = _tile(new_features, 'targets_psr', [num_classes, 1, 1])\n","  inp_target_dim = [num_classes, 1, 1, 1] if out == 'cmd' else [num_classes, 1]\n","  new_features = _tile(new_features, 'inputs', inp_target_dim)\n","  new_features = _tile(new_features, 'targets', inp_target_dim)\n","\n","  # run model\n","  output_batch = infer_from_bottleneck(\n","      new_features, bottleneck1, model, out=out)\n","  \n","  # render outputs and show results\n","  output_batch = output_batch[0] if out == 'img' else output_batch['outputs']\n","  for output in tf.split(output_batch, num_classes):\n","    output_stream.add_output(output)\n","    if output_stream.ax_id == 10:\n","      [output_stream.add_white() for _ in range(16)]\n","  \n","  output_stream.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"93Shi6q00bHv"},"source":["# Running"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":115784,"status":"ok","timestamp":1568423903171,"user":{"displayName":"","photoUrl":"","userId":""},"user_tz":420},"id":"RICzTkcV3B3x","outputId":"8c230811-bf33-44aa-a8a0-4938f03899bf","colab":{"height":1000}},"source":["# vae trained on external data, tested with external data\n","problem = 'glyph_azzn_problem'\n","data_dir = 'svg_vae_data/final-font-dataset/'\n","model_name = 'svg_decoder'  # or svg_decoder\n","hparam_set = 'svg_decoder'  # or svg_decoder\n","hparams = \"\"\n","ckpt_dir = 'saved_models/svg_decoder_g2g/'\n","out = 'img' if model_name == 'image_vae' else 'cmd'\n","\n","print('class switch')\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=101)\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=103)\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=165)\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=195)\n","\n","# print('interpolation')\n","# interpolation(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","#               out=out, ex_id=101, ex_id2=(102-101))\n","# interpolation(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","#               out=out, ex_id=96, ex_id2=(172-96))\n","\n","# print('random z per class')\n","# random_bottleneck(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","#                   out=out)\n","# random_bottleneck(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","#                   out=out)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":108793,"status":"ok","timestamp":1568424012011,"user":{"displayName":"","photoUrl":"","userId":""},"user_tz":420},"id":"ocYxlcfWxvgk","outputId":"f32ae60e-fd32-4e0f-bd46-eba5f9b1809f","colab":{"height":1000}},"source":["# vae trained on internal data, tested with internal data\n","problem = 'glyph_azzn_problem'\n","data_dir = '/path/to/internal_data/'\n","model_name = 'image_vae'  # or svg_decoder\n","hparam_set = 'image_vae'  # or svg_decoder\n","hparams = \"\"\n","ckpt_dir = '/path/to/image_vae_internal/'\n","out = 'img' if model_name == 'image_vae' else 'cmd'\n","\n","print('class switch')\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=131)\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=120)\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=68)\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=69)\n","\n","\n","print('interpolation')\n","interpolation(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","              out=out, ex_id=131, ex_id2=(184-131))\n","interpolation(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","              out=out, ex_id=172, ex_id2=(198-172))\n","\n","print('random z per class')\n","random_bottleneck(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","                  out=out)\n","random_bottleneck(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","                  out=out)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":115590,"status":"ok","timestamp":1568424127634,"user":{"displayName":"","photoUrl":"","userId":""},"user_tz":420},"id":"nUYZyQhKvXux","outputId":"6129738f-b8c6-41a3-8219-4ace3b5d1d36","colab":{"height":1000}},"source":["# vae trained on internal data, tested with external data\n","problem = 'glyph_azzn_problem'\n","data_dir = '/path/to/external_data/'\n","model_name = 'image_vae'  # or svg_decoder\n","hparam_set = 'image_vae'  # or svg_decoder\n","hparams = \"\"\n","ckpt_dir = '/path/to/image_vae_internal/'\n","out = 'img' if model_name == 'image_vae' else 'cmd'\n","\n","print('class switch')\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=101)\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=103)\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=165)\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=195)\n","\n","print('interpolation')\n","interpolation(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","              out=out, ex_id=101, ex_id2=(102-101))\n","interpolation(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","              out=out, ex_id=96, ex_id2=(172-96))\n","\n","print('random z per class')\n","random_bottleneck(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","                  out=out)\n","random_bottleneck(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","                  out=out)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":228374,"status":"ok","timestamp":1568424356103,"user":{"displayName":"","photoUrl":"","userId":""},"user_tz":420},"id":"7uXKh2Dcl1do","outputId":"cb556dbb-4eef-4f6b-a4db-e9d73640f1b8","colab":{"height":1000}},"source":["# svg trained on external data, tested with external data\n","problem = 'glyph_azzn_problem'\n","data_dir = '/path/to/external_data/'\n","model_name = 'svg_decoder'  # or image_vae\n","hparam_set = 'svg_decoder'  # or image_vae\n","hparams = (\"vae_ckpt_dir=/path/to/image_vae_external,\"\n","           \"vae_data_dir=/path/to/external_data,vae_hparam_set=image_vae\")\n","ckpt_dir = '/path/to/svg_decoder_external'\n","out = 'cmd'\n","\n","# you can control sampling variance by changing the temperatures here\n","new_hparams = 'mix_temperature={},gauss_temperature={}'.format(0.0001, 0.0001)\n","hparams = hparams + ',' + new_hparams\n","print('using {}'.format(new_hparams))\n","\n","print('class switch')\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=101)\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=103)\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=165)\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=195)\n","\n","print('interpolation')\n","interpolation(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","              out=out, ex_id=101, ex_id2=(102-101))\n","interpolation(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","              out=out, ex_id=96, ex_id2=(172-96))\n","\n","print('random z per class')\n","random_bottleneck(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","                  out=out)\n","random_bottleneck(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","                  out=out)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":242687,"status":"ok","timestamp":1568424598832,"user":{"displayName":"","photoUrl":"","userId":""},"user_tz":420},"id":"8Na9kzO3lQ0x","outputId":"c17598aa-c39a-4853-a4c1-7f9ac2d01ee3","colab":{"height":1000}},"source":["# svg trained on internal data, tested with internal data\n","problem = 'glyph_azzn_problem'\n","data_dir = '/path/to/internal_data/'\n","model_name = 'svg_decoder'  # or image_vae,\n","hparam_set = 'svg_decoder'  # or image_vae,\n","hparams = (\"vae_ckpt_dir=/path/to/image_vae_internal,\"\n","           \"vae_data_dir=/path/to/internal_data,vae_hparam_set=image_vae\")\n","ckpt_dir = '/path/to/svg_decoder_internal'\n","out = 'cmd'\n","\n","# you can control sampling variance by changing the temperatures here\n","new_hparams = 'mix_temperature={},gauss_temperature={}'.format(0.0001, 0.0001)\n","hparams = hparams + ',' + new_hparams\n","print('using {}'.format(new_hparams))\n","\n","print('class switch')\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=131)\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=120)\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=68)\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=69)\n","\n","\n","print('interpolation')\n","interpolation(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","              out=out, ex_id=131, ex_id2=(184-131))\n","interpolation(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","              out=out, ex_id=172, ex_id2=(198-172))\n","\n","print('random z per class')\n","random_bottleneck(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","                  out=out)\n","random_bottleneck(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","                  out=out)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":223380,"status":"ok","timestamp":1568424822324,"user":{"displayName":"","photoUrl":"","userId":""},"user_tz":420},"id":"KS_bNS3CvLPF","outputId":"f3579c48-2382-44a2-a72d-3de135c5eff6","colab":{"height":1000}},"source":["# svg trained on internal data, tested with external data\n","problem = 'glyph_azzn_problem'\n","data_dir = '/path/to/external_data/'\n","model_name = 'svg_decoder'  # or image_vae,\n","hparam_set = 'svg_decoder'  # or image_vae,\n","hparams = (\"vae_ckpt_dir=/path/to/image_vae_internal,\"\n","           \"vae_data_dir=/path/to/internal_data,vae_hparam_set=image_vae\")\n","ckpt_dir = '/path/to/svg_decoder_internal'\n","out = 'cmd'\n","\n","# you can control sampling variance by changing the temperatures here\n","new_hparams = 'mix_temperature={},gauss_temperature={}'.format(0.0001, 0.0001)\n","hparams = hparams + ',' + new_hparams\n","print('using {}'.format(new_hparams))\n","\n","print('class switch')\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=101)\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=103)\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=165)\n","class_switch(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","             out=out, split=Modes.TRAIN, ex_id=195)\n","\n","print('interpolation')\n","interpolation(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","              out=out, ex_id=101, ex_id2=(102-101))\n","interpolation(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","              out=out, ex_id=96, ex_id2=(172-96))\n","\n","print('random z per class')\n","random_bottleneck(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","                  out=out)\n","random_bottleneck(problem, data_dir, hparam_set, hparams, model_name, ckpt_dir,\n","                  out=out)"],"execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"Copy of playing with magenta vae","provenance":[{"file_id":"/piper/depot/google3/third_party/py/magenta/models/svg_vae/decoding.ipynb?workspaceId=iraphael:fig-export-dev-change-54-1cc47efa03b3::citc","timestamp":1568758807713},{"file_id":"1tIEoA9aNaQ1G8LrvOj1OU4N8gGh0MNMU","timestamp":1567712980131},{"file_id":"17FMYlIPEIu0qP-IB0ko1BbPsuZzRf7R_","timestamp":1566847141824}],"collapsed_sections":["I-RBCz5S2gD1","hMUYnd3NtnF3","3XtY17EajF71","doR9EP687k_X","TX7aEQlJjJ95","NnYl0KJUs3qg","50DnLHavviED"],"last_runtime":{"build_target":"//learning/deepmind/dm_python:dm_notebook","kind":"private"}},"kernelspec":{"display_name":"Python 3.6.10 64-bit ('magenta': conda)","name":"python361064bitmagentaconda4a691222971146afb53c6e5bd2c740aa"}},"nbformat":4,"nbformat_minor":0}